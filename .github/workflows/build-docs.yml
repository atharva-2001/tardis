#  For more information about TARDIS pipelines, please refer to:
#
#    https://tardis-sn.github.io/tardis/contributing/development/continuous_integration.html

name: docs

on:
  push:
    branches:
      - master

  pull_request:
    branches:
      - '*'

  # pull_request_target:
  #   branches:
  #     - master

  #   types:
  #     - opened
  #     - reopened
  #     - synchronize
  #     - labeled # requires the `build-docs` label
  #     - ready_for_review

  workflow_dispatch: # manual trigger

env:
  CACHE_NUMBER: 0 # increase to reset cache manually
  DEPLOY_BRANCH: gh-pages # deployed docs branch
  HDF5_USE_FILE_LOCKING: "FALSE" # disable file locking

# concurrency:
#   group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}
#   cancel-in-progress: true

defaults:
  run:
    shell: bash -l {0}

jobs:
  test-cache:
    uses: ./.github/workflows/lfs-cache.yml
    with:
      atom-data-sparse: true
      regression-data-repo: tardis-sn/tardis-regression-data
      allow_lfs_pull: ${{ github.ref == 'refs/heads/master' || contains(github.event.pull_request.labels.*.name, 'git-lfs-pull') }}

  check-for-changes:
    runs-on: ubuntu-latest
    if: ${{ !github.event.pull_request.draft }}
    outputs:
      trigger-check-outcome: ${{ steps.trigger_check.outcome }}
      docs-check-outcome: ${{ steps.docs_check.outcome }}
    steps:
      - uses: actions/checkout@v4
        if: github.event_name != 'pull_request_target'

      - name: Checkout pull/${{ github.event.number }}
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event.pull_request.head.sha }}
        if: github.event_name == 'pull_request_target'

      - name: Check for trigger by push event, manual dispatch, build-docs label on a PR
        id: trigger_check
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch' || github.event_name == 'pull_request_target' && contains(github.event.pull_request.labels.*.name, 'build-docs')
        run: |
          echo "Building docs as a test."
          exit 0
        continue-on-error: true

      - name: Check for changes in documentation
        run: |
          if git diff origin/master..."$(git rev-parse --abbrev-ref HEAD)" --name-only | cat | grep '^docs/' | grep -q .; then
              num_files=$(git diff --name-only origin/master...HEAD | grep '^docs/' | wc -l)
              echo "Changes found in documentation files: $num_files"
              exit 0
          else
              echo "No changes found in documentation files - will stop running the pipeline."
              exit 1
          fi
        id: docs_check
        if: steps.trigger_check.outcome != 'success'
        continue-on-error: true

  build-docs:
    runs-on: ubuntu-latest
    # needs: [test-cache, check-for-changes]
    # if: needs.check-for-changes.outputs.trigger-check-outcome == 'success' || needs.check-for-changes.outputs.docs-check-outcome == 'success'
    strategy:
      fail-fast: false
      matrix:
        folder: [
          'analysing_tardis_outputs',
          'analyzing_tardis',
          'api',
          'contributing',
          'graphics',
          'io',
          'physics',
          'resources',
          'workflows'
        ]
    steps:
      - uses: actions/checkout@v4
        if: github.event_name != 'pull_request_target'

      - name: Checkout pull/${{ github.event.number }}
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha }}
        if: github.event_name == 'pull_request_target'

      - name: Setup LFS
        uses: ./.github/actions/setup_lfs
        with:
          atom-data-sparse: true

      - name: Setup environment
        uses: ./.github/actions/setup_env
        with:
          os-label: linux-64

      - name: Copy atom_data
        run: |
          mkdir -p ~/Downloads/tardis-data && cp -a ./tardis-regression-data/atom_data/. ~/Downloads/tardis-data

      - name: Install package
        run: pip install -e .

      - name: Install Sphinx extensions
        run: |
          pip install sphinxcontrib-googleanalytics

      - name: Build documentation for ${{ matrix.folder }}
        run: |
          mkdir -p temp_docs/${{ matrix.folder }}
          cp docs/conf.py temp_docs/
          cp docs/index.rst temp_docs/
          cp docs/faq.rst temp_docs/
          cp docs/installation.rst temp_docs/
          cp docs/make.bat temp_docs/
          cp docs/Makefile temp_docs/
          cp docs/tardis.bib temp_docs/
          cp docs/tardis_example.yml temp_docs/
          cp docs/tardis_logo.ico temp_docs/
          cp docs/tutorials.rst temp_docs/
          cp docs/quickstart.ipynb temp_docs/ || true
          cp docs/multiindex_isotope_decay_data.ipynb temp_docs/ || true
          
          # Copy just the specific folder from the matrix
          cp -r docs/${{ matrix.folder }} temp_docs/
          
          # Build the documentation
          cd temp_docs/ && make html NCORES=auto

