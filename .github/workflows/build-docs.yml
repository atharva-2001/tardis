#  For more information about TARDIS pipelines, please refer to:
#
#    https://tardis-sn.github.io/tardis/contributing/development/continuous_integration.html

name: docs

on:
  push:
    branches:
      - master

  pull_request:
    branches:
      - '*'

  # pull_request_target:
  #   branches:
  #     - master

  #   types:
  #     - opened
  #     - reopened
  #     - synchronize
  #     - labeled # requires the `build-docs` label
  #     - ready_for_review

  workflow_dispatch: # manual trigger

env:
  CACHE_NUMBER: 0 # increase to reset cache manually
  DEPLOY_BRANCH: gh-pages # deployed docs branch
  HDF5_USE_FILE_LOCKING: "FALSE" # disable file locking

# concurrency:
#   group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}
#   cancel-in-progress: true

defaults:
  run:
    shell: bash -l {0}

jobs:
  test-cache:
    uses: ./.github/workflows/lfs-cache.yml
    with:
      atom-data-sparse: true
      regression-data-repo: tardis-sn/tardis-regression-data
      allow_lfs_pull: ${{ github.ref == 'refs/heads/master' || contains(github.event.pull_request.labels.*.name, 'git-lfs-pull') }}

  check-for-changes:
    runs-on: ubuntu-latest
    if: ${{ !github.event.pull_request.draft }}
    outputs:
      trigger-check-outcome: ${{ steps.trigger_check.outcome }}
      docs-check-outcome: ${{ steps.docs_check.outcome }}
    steps:
      - uses: actions/checkout@v4
        if: github.event_name != 'pull_request_target'

      - name: Checkout pull/${{ github.event.number }}
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event.pull_request.head.sha }}
        if: github.event_name == 'pull_request_target'

      - name: Check for trigger by push event, manual dispatch, build-docs label on a PR
        id: trigger_check
        if: github.event_name == 'push' || github.event_name == 'workflow_dispatch' || github.event_name == 'pull_request_target' && contains(github.event.pull_request.labels.*.name, 'build-docs')
        run: |
          echo "Building docs as a test."
          exit 0
        continue-on-error: true

      - name: Check for changes in documentation
        run: |
          if git diff origin/master..."$(git rev-parse --abbrev-ref HEAD)" --name-only | cat | grep '^docs/' | grep -q .; then
              num_files=$(git diff --name-only origin/master...HEAD | grep '^docs/' | wc -l)
              echo "Changes found in documentation files: $num_files"
              exit 0
          else
              echo "No changes found in documentation files - will stop running the pipeline."
              exit 1
          fi
        id: docs_check
        if: steps.trigger_check.outcome != 'success'
        continue-on-error: true

  build-docs:
    name: Build docs (${{ matrix.folder }})
    runs-on: ubuntu-latest
    # needs: [test-cache, check-for-changes]
    # if: needs.check-for-changes.outputs.trigger-check-outcome == 'success' || needs.check-for-changes.outputs.docs-check-outcome == 'success'
    strategy:
      fail-fast: false
      matrix:
        folder: [
          'io/configuration',
          'io/grid',
          'io/hdf',
          'io/images',
          'io/model',
          'io/optional',
          'io/output'
        ]
    steps:
      - uses: actions/checkout@v4
        if: github.event_name != 'pull_request_target'

      - name: Checkout pull/${{ github.event.number }}
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha }}
        if: github.event_name == 'pull_request_target'

      - name: Setup LFS
        uses: ./.github/actions/setup_lfs
        with:
          atom-data-sparse: true

      - name: Setup environment
        uses: ./.github/actions/setup_env
        with:
          os-label: linux-64

      - name: Copy atom_data
        run: |
          mkdir -p ~/Downloads/tardis-data && cp -a ./tardis-regression-data/atom_data/. ~/Downloads/tardis-data

      - name: Install package
        run: pip install -e .

      - name: Install Sphinx extensions
        run: |
          pip install sphinxcontrib-googleanalytics

      - name: Setup documentation structure for ${{ matrix.folder }}
        run: |
          # Prepare base directory structure
          mkdir -p temp_docs/
          cp docs/conf.py temp_docs/
          cp docs/index.rst temp_docs/
          cp docs/faq.rst temp_docs/
          cp docs/installation.rst temp_docs/
          cp docs/make.bat temp_docs/
          cp docs/Makefile temp_docs/
          cp docs/tardis.bib temp_docs/
          cp docs/tardis_example.yml temp_docs/
          cp docs/tardis_logo.ico temp_docs/
          cp docs/tutorials.rst temp_docs/
          cp docs/quickstart.ipynb temp_docs/ || true
          cp docs/multiindex_isotope_decay_data.ipynb temp_docs/ || true
          cp docs/io/tardis_example.yml temp_docs/ || true
          
          # Always copy _static and _templates folders
          if [ -d "docs/_static" ]; then
            mkdir -p temp_docs/_static
            cp -r docs/_static/* temp_docs/_static/ 2>/dev/null || true
          fi
          
          if [ -d "docs/_templates" ]; then
            mkdir -p temp_docs/_templates
            cp -r docs/_templates/* temp_docs/_templates/ 2>/dev/null || true
          fi
          
          # Create nested directory structure if needed
          if [[ "${{ matrix.folder }}" == io/* ]]; then
            # Extract subfolder name
            SUBFOLDER=$(echo "${{ matrix.folder }}" | sed 's|io/||')
            echo "Processing IO subfolder: $SUBFOLDER"
            
            # Create io directory and copy any io-related files
            mkdir -p temp_docs/io
            find docs/io -maxdepth 1 -type f -exec cp {} temp_docs/io/ \;
            
            # Ensure we have at least an index.rst
            if [ ! -f temp_docs/io/index.rst ]; then
              echo "Creating placeholder index.rst for io folder"
              echo "==========\nIO Module\n==========\n\n.. toctree::\n   :maxdepth: 2\n\n   $SUBFOLDER/index\n" > temp_docs/io/index.rst
            fi
            
            # Copy just the specific subfolder
            mkdir -p temp_docs/io/$SUBFOLDER
            cp -r docs/io/$SUBFOLDER/* temp_docs/io/$SUBFOLDER/ 2>/dev/null || true
            
            # Create placeholder index.rst in subfolder if it doesn't exist
            if [ ! -f temp_docs/io/$SUBFOLDER/index.rst ]; then
              echo "Creating placeholder index.rst for io/$SUBFOLDER"
              echo "======================\n$SUBFOLDER Documentation\n======================\n\n.. toctree::\n   :maxdepth: 2\n\n" > temp_docs/io/$SUBFOLDER/index.rst
            fi
          else
            # For non-io folders (_static, _templates)
            cp -r docs/${{ matrix.folder }} temp_docs/
          fi
        env:
          MATRIX_FOLDER: ${{ matrix.folder }}
          
      - name: List contents of temp_docs directory
        run: |
          echo "======= CONTENTS OF TEMP_DOCS ======="
          find temp_docs -type f | sort
          echo "\n======= DIRECTORY STRUCTURE ======="
          find temp_docs -type d | sort
          
      - name: Build documentation
        run: |
          cd temp_docs/ && make html NCORES=auto
          
      - name: Print Sphinx error logs
        if: failure()
        run: |
          echo "======= SPHINX ERROR LOGS ======="
          for errfile in /tmp/sphinx-err-*; do
            if [ -f "$errfile" ]; then
              echo "Contents of $errfile:"
              cat "$errfile"
              echo "\n----------------------\n"
            else
              echo "No Sphinx error files found"
            fi
          done

